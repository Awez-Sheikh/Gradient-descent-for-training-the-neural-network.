# Gradient-descent-for-training-the-neural-network.
Neural Network Training on MNIST & Fashion MNIST
This project explores the training of neural networks using the gradient descent algorithm on two datasets: MNIST (handwritten digits) and Fashion MNIST (clothing categories). The objective is to optimize classification performance through architectural and functional experimentation.

Key Objectives:
1.Datasets: MNIST and Fashion MNIST (28x28 grayscale images, 10 classes).
2.Learning Algorithm: Gradient Descent.
3.Architectural Experiments:
  a.Vary number of hidden layers and neurons.
  b.Apply dropout and batch normalization.
4.Activation Functions:
  a.Hidden layers: ReLU, Sigmoid, Tanh.
  b.Output layer: Softmax (for multi-class classification).
5.Evaluation Metrics:
  a.Training & validation accuracy.
  b.Loss convergence & training time.
  c.Overfitting vs. generalization analysis.
